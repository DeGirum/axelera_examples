{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running multiple models with warm-up\n",
        "\n",
        "This notebook demonstrates how to load and run multiple AI models using DeGirum PySDK on a Hailo-8 or Hailo-8L device.\n",
        "\n",
        "It showcases the model warm-up technique, which involves running a single dummy inference on each model after loading. This step ensures all runtime resources and tensor buffers are initialized, which avoids latency spikes during the first real inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Necessary imports and loading models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "6hJTRobOV-9C",
        "outputId": "bac9a248-1cf8-4c00-9852-a563f941ebbd"
      },
      "outputs": [],
      "source": [
        "import cv2, numpy as np, degirum as dg, degirum_tools, time\n",
        "from PIL import Image\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 1. SETUP\n",
        "# ------------------------------------------------------------------\n",
        "host = \"@cloud\"\n",
        "zoo = \"degirum/axelera\"\n",
        "device_type = \"AXELERA/METIS\"\n",
        "token='dg_AunvRo5k1FNaH7jqzziPKrFoCFD9JRf1nC3L1'\n",
        "pose_model_name = \"yolov8n_relu6_face_kpts--640x640_quant_axelera_metis_1\"\n",
        "face_model_name = \"yolov8n_relu6_face--640x640_quant_axelera_metis_1\"\n",
        "#TODO check dequantize postprocessor error\n",
        "face_vec_model_name = \"mbf--112x112_quant_axelera_metis_1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comparing latency with warmup and without warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First inference (no warm-up): 690.9 ms\n",
            "Subsequent inference (warmed up): 634.6 ms\n"
          ]
        }
      ],
      "source": [
        "# Load a Hailo model\n",
        "model = dg.load_model(\n",
        "    model_name=pose_model_name,\n",
        "    inference_host_address=host,\n",
        "    token=token,\n",
        "    zoo_url=zoo,\n",
        "    device_type=device_type\n",
        ")\n",
        "\n",
        "dummy_input = np.zeros((640,640,3), dtype=np.uint8)\n",
        "\n",
        "# --- Inference WITHOUT warm-up ---\n",
        "start = time.time()\n",
        "_ = model(dummy_input)\n",
        "t1 = time.time() - start\n",
        "print(f\"First inference (no warm-up): {t1*1000:.1f} ms\")\n",
        "\n",
        "# --- Inference WITH warm-up ---\n",
        "_ = model(dummy_input)  # warm-up step\n",
        "\n",
        "start = time.time()\n",
        "_ = model(dummy_input)\n",
        "t2 = time.time() - start\n",
        "print(f\"Subsequent inference (warmed up): {t2*1000:.1f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-model inference pipeline with warmup\n",
        "\n",
        "\n",
        "We run Pose detection continuously on every frame. If a dummy condition is met (e.g., more than one person detected), we run face detection model to localize faces and then we use face embedding (vector) model on each detected face. This showcases how using a dummy inference reduces latency while model switching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Loading models and running warm-up inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading models...\n",
            "Warming up models...\n"
          ]
        },
        {
          "ename": "DegirumException",
          "evalue": "Failed to perform model 'degirum/axelera/mbf--112x112_quant_axelera_metis_1' inference: Postprocessor type 'Dequantization' is not known",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mDegirumException\u001b[0m                          Traceback (most recent call last)",
            "\u001b[1;31mDegirumException\u001b[0m: Postprocessor type 'Dequantization' is not known",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mDegirumException\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m PoseModel(dummy_pose_img)\n\u001b[0;32m     14\u001b[0m FaceModel(dummy_face_img)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mFaceVectorModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_face_crop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarm-up complete. Models are ready for real-time inference.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\degirum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\degirum\\log.py:92\u001b[0m, in \u001b[0;36mlog_wrap.<locals>.sync_wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(log_level, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n",
            "File \u001b[1;32mc:\\Users\\degirum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\degirum\\model.py:237\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;129m@log_wrap\u001b[39m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[0;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform whole inference lifecycle: input data preprocessing, inference and postprocessing.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m    Same as [degirum.model.Model.predict][].\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\degirum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\degirum\\log.py:92\u001b[0m, in \u001b[0;36mlog_wrap.<locals>.sync_wrap\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     logger\u001b[38;5;241m.\u001b[39mlog(log_level, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n",
            "File \u001b[1;32mc:\\Users\\degirum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\degirum\\model.py:228\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;129m@log_wrap\u001b[39m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msource\u001b[39m():\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, data)\n\u001b[1;32m--> 228\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_impl(source))\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\degirum\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\degirum\\model.py:1233\u001b[0m, in \u001b[0;36mModel._predict_impl\u001b[1;34m(self, sources)\u001b[0m\n\u001b[0;32m   1231\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to perform model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m inference: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(saved_exception)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1232\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(saved_exception\u001b[38;5;241m.\u001b[39mtraceback)\n\u001b[1;32m-> 1233\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m DegirumException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msaved_exception\u001b[39;00m\n",
            "\u001b[1;31mDegirumException\u001b[0m: Failed to perform model 'degirum/axelera/mbf--112x112_quant_axelera_metis_1' inference: Postprocessor type 'Dequantization' is not known"
          ]
        }
      ],
      "source": [
        "print(\"Loading models...\")\n",
        "PoseModel = dg.load_model(model_name=pose_model_name, inference_host_address=host, zoo_url=zoo, token=token, device_type=device_type)\n",
        "FaceModel = dg.load_model(model_name=face_model_name, inference_host_address=host, zoo_url=zoo, token=token, device_type=device_type)\n",
        "FaceVectorModel = dg.load_model(model_name=face_vec_model_name, inference_host_address=host, zoo_url=zoo, token=token, device_type=device_type)\n",
        "\n",
        "\n",
        "# Dummy image for warm-up\n",
        "dummy_pose_img = np.zeros((640,640,3), dtype=np.uint8)\n",
        "dummy_face_img = np.zeros((640,640,3), dtype=np.uint8)\n",
        "dummy_face_crop = np.zeros((112,112,3), dtype=np.uint8)\n",
        "\n",
        "print(\"Warming up models...\")\n",
        "PoseModel(dummy_pose_img)\n",
        "FaceModel(dummy_face_img)\n",
        "FaceVectorModel(dummy_face_crop)\n",
        "\n",
        "print(\"Warm-up complete. Models are ready for real-time inference.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Running inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbWu3KReY6uA"
      },
      "outputs": [],
      "source": [
        "combined_model = degirum_tools.CombiningCompoundModel(PoseModel, FaceModel)\n",
        "inference_stream = degirum_tools.predict_stream(combined_model, 0)\n",
        "\n",
        "with degirum_tools.Display(\"Results\") as display:\n",
        "    for inference_result in inference_stream:\n",
        "        annotated_frame = inference_result.image_overlay.copy()  # copy to modify\n",
        "\n",
        "        for detection in inference_result.results:\n",
        "            if detection.get(\"label\") == \"face\" and \"bbox\" in detection:\n",
        "                print(\"\\n ------- POSE + FACE DETECTION RESULT -------\")\n",
        "                print(f\"- Detected: {detection['label']} at {detection.get('bbox', 'N/A')}\")\n",
        "                x1, y1, x2, y2 = map(int, detection[\"bbox\"])\n",
        "                face_crop = annotated_frame[y1:y2, x1:x2]\n",
        "\n",
        "                if face_crop.shape[0] > 0 and face_crop.shape[1] > 0:\n",
        "                    face_resized = cv2.resize(face_crop, (112, 112))\n",
        "                    vec_result = FaceVectorModel(face_resized)\n",
        "                    embedding = np.asarray(vec_result.results[0][\"data\"]).flatten()\n",
        "\n",
        "                    emb_id = embedding[0]\n",
        "                    emb_norm = np.linalg.norm(embedding)\n",
        "                    label_text = f\"VecID: {emb_id:.2f}, Norm: {emb_norm:.2f}\"\n",
        "\n",
        "                    # Print embedding debug info\n",
        "                    print(\"\\n -------- FACE VECTOR RESULT ----------\")\n",
        "                    print(f\"Embedding Length: {len(embedding)}\")\n",
        "                    print(f\"First 5 Vector Values: {embedding[:5]}\")\n",
        "                    print(f\"Norm: {emb_norm:.2f}\")\n",
        "\n",
        "                    # Draw label and box using OpenCV\n",
        "                    cv2.putText(annotated_frame, label_text, (x1, y1 - 10),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
        "                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (255, 255, 0), 1)\n",
        "\n",
        "        display.show(annotated_frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
