{
  "quantized_model_file": "quantized_model.json",
  "quantize_params": [
    [
      0.003921568859368563,
      -128
    ]
  ],
  "dequantize_params": [
    [
      0.09124253690242767,
      -61
    ],
    [
      0.07068484276533127,
      -60
    ],
    [
      0.07063177973031998,
      -45
    ],
    [
      0.08594972640275955,
      153
    ],
    [
      0.13518203794956207,
      118
    ],
    [
      0.16721206903457642,
      111
    ]
  ],
  "input_names": [
    "x"
  ],
  "input_shapes": [
    [
      1,
      642,
      656,
      4
    ]
  ],
  "input_dtypes": [
    "int8"
  ],
  "output_shapes": [
    [
      1,
      80,
      80,
      64
    ],
    [
      1,
      40,
      40,
      64
    ],
    [
      1,
      20,
      20,
      64
    ],
    [
      1,
      80,
      80,
      128
    ],
    [
      1,
      40,
      40,
      128
    ],
    [
      1,
      20,
      20,
      128
    ]
  ],
  "output_dtypes": [
    "int8",
    "int8",
    "int8",
    "int8",
    "int8",
    "int8"
  ],
  "model_lib_file": "model.json",
  "model_params_file": "params.bin",
  "n_padded_ch_inputs": [
    [
      0,
      0,
      1,
      1,
      1,
      15,
      0,
      1
    ]
  ],
  "n_padded_ch_outputs": [
    [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      0
    ],
    [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      48
    ],
    [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      48
    ],
    [
      0,
      0,
      0,
      0,
      0,
      0,
      0,
      48
    ]
  ],
  "input_tensor_layout": "NHWC",
  "preprocess_graph": null,
  "postprocess_graph": "postprocess_graph.onnx",
  "manifest_version": "1.0"
}